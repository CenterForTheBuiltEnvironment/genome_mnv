---
title: "Reliability Demonstration of A Novel Randomized Measurement and Verification Method for Switchable Control Retrofit Using Large-scale Public Dataset"
author:
  - Aoyu Zou ^[Center for the Built Environment, University of California Berkeley, USA], Paul Raftery ^1^, Stefano Schiavon ^1^, Carlos Durate ^1^
abstract: Conventional measurement and verification (M&V) methods relying on pre- and post-  retrofit comparison for estimating whole-building energy savings are often time-consuming and unreliable, especially when non-routine events such as reduced occupancy occur during the M&V process. Those events are unrelated to the intervention but significantgly affect building energy consumption and thus when the analyst applies conventiona M&V suggested by industry guidelines, the results can be largely confounded. In this study, we demonstrated that switchable interventions, such as most of the control retrofits, can benefit from random sampling, where the analyst randomly selects whether to implement the baseline or the intervention strategy each day. We tested this novel randomized M&V method on a large public dataset covering various climate zones and commercial building types, using a virtual chilled water supply temperature reset based on outdoor weather as the intervention. Our results show that comparing to the conventional method, the randomized method provides faster and more accurate savings estimation. Additionaly we found that the randomized M&V approach estimates much closer to the true savings when non-routine events are present demonstrating much improved reliability.

output:
  bookdown::word_document2:
    reference_docx: "../paper/template.docx"
editor_options: 
  markdown: 
    wrap: 72
bibliography: references.bib
biblio-style: apalike

knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = "../paper"
    )
  })
---

```{r setup, include = FALSE, cache = FALSE}

# knitr setup
knitr::opts_chunk$set(echo = F, 
                      message = F,
                      warning = F,
                      dev = "jpeg",
                      # cache = T,
                      dpi = 300,
                      fig.show = "hold",
                      fig.pos = "b", 
                      fig.path = "../figs/manuscript/figs/")

# str(knitr::opts_chunk$get()) # see for all options

```

```{r prep, include = FALSE, cache = FALSE}
#### LIBRARIES ####
require(pacman)

# load packages using pacman
pacman::p_load(tidyverse, lubridate, here, stats, zoo, scales, ggpubr, patchwork, RColorBrewer)

# turn off scientific notation
options(scipen = 999, digits = 15)

# set directory
here::i_am("manuscript.rmd")

# set default theme for ggplot
theme_set(theme_minimal())

# define base ggplot theme
theme_update(plot.title = element_text(size = 14, colour = "grey20", face = "bold", hjust = 0.5),
             plot.subtitle = element_text(size = 10, colour = "grey20", face = "italic", hjust = 0.5, margin = margin(b = 10)),
             plot.caption = element_text(size = 10, colour = "grey20", face = "italic", hjust = 0.5),
             plot.background = element_rect(fill = "white", colour = NA),
             panel.grid.minor = element_blank(),
             panel.grid.major = element_blank(),
             axis.text = element_text(size = 10),
             strip.text = element_text(size = 10, color = "grey20", face = "bold"),
             strip.background = element_blank())

# colors
ls_colors <- c("Baseline" = "#c6dbef",
               "Measured baseline" = "#c6dbef",
               "Adjusted baseline" = "#c6dbef",
               "Projected baseline" = "#2171b5",
               "Intervention" = "#fdbb84",
               "Measured interv" = "#fdbb84",
               "Conventional M&V" = "grey70", 
               "Randomized M&V" = "#66c2a4", 
               "Buildings satisfying all criteria" = "#66c2a4", 
               "Buildings satisfying 80% TMY range" = "black", 
               "Buildings satisfying SPRT" = "black")

# parameters
ctr_params <- list(peak_hours = 10:16,
                   chwl_perc = 0.25,
                   step_perc = 0.08,
                   conv_swt = 6,
                   weather_knots = c(15, 25),
                   swt_knots = c(12, 7),
                   coe_peak = 0.8,
                   coe_off = 1.2,
                   enable_temp = 8)

occ_params <- list(change_start = 5,
                   change_end = 8,
                   change = 20)





#### FUNCTIONS ####
# Function defined to read downloaded tmy files
get_tmy <- function(all_sites, readfile_path){
  
  df_tmy <- data.frame()
  
  for (site in all_sites){
    df <- read_csv(paste0(readfile_path, "tmy/", str_glue("{site}.epw")),
                   skip = 8, col_types = "ddddd-d---------------------------------",
                   col_names = c("year", "month", "day", "hour", "min", "tmy")) %>%
      mutate(year = 2017,
             time = ymd_h(paste(paste(year, month, day, sep = "-"), hour, sep = " ")),
             temp = tmy) %>%
      dplyr::select(time, temp) %>% 
      mutate(site = site)
    
    df_tmy <- rbind(df_tmy, df)
  }
  
  return(df_tmy)
}

# Function defined to add chwst reset intervention
run_reset <- function(df_baseline){
  
  mean <- mean(df_baseline$base_eload, na.rm = T) * ctr_params$chwl_perc
  
  grad <- (ctr_params$swt_knots[2] - ctr_params$swt_knots[1]) / 
    (ctr_params$weather_knots[2] - ctr_params$weather_knots[1])
  
  interc <- ctr_params$swt_knots[2] - (ctr_params$weather_knots[2] * grad)
  
  df_interv <- df_baseline %>% 
    mutate(swt = t_out * grad + interc, 
           chwl = mean,
           hour = hour(datetime)) %>% 
    mutate(swt = ifelse(swt > ctr_params$swt_knots[1], ctr_params$swt_knots[1], ifelse(swt < ctr_params$swt_knots[2], ctr_params$swt_knots[2], swt)), 
           temp_savings = ifelse(t_out >= ctr_params$enable_temp, (swt - ctr_params$conv_swt) * ctr_params$step_perc, 0), 
           time_adj = ifelse(hour %in% ctr_params$peak_hours, ctr_params$coe_peak, ctr_params$coe_off), 
           perc_savings = temp_savings * time_adj, 
           savings = chwl * perc_savings, 
           interv_eload = base_eload - savings) %>% 
    select(datetime, base_eload, interv_eload, t_out)
  
  return(df_interv)
}

# Function defined to interpolate NAs
run_interpo <- function(df_all){
  
  na_counts <- df_all %>%
    mutate(date = date(timestamp)) %>%
    group_by(date) %>%
    summarize(na_hours = sum(is.na(eload)))
  
  # Filter out days with more than half of the hours having NAs
  valid_days <- na_counts %>%
    filter(na_hours <= 12) %>%
    pull(date)
  
  df_filtered <- df_all %>%
    filter(date(timestamp) %in% valid_days)
  
  df_filtered <- df_filtered %>%
    mutate(across(c(eload, t_out), ~ zoo::na.approx(., na.rm = FALSE))) %>% 
    rename(datetime = timestamp, 
           base_eload = eload)
  
  return(df_filtered)
}

# Function defined to adjust the plot scale
get_scale <- function(eload, range = 2){
  
  min_y <- mean(eload, na.rm = T) - range * sd(eload, na.rm = T)
  max_y <- mean(eload, na.rm = T) + range * sd(eload, na.rm = T)
  
  return(c(min_y, max_y))
}
```

```{r readdata, include=FALSE}

#### READ DATA ####
df_loc <- read.csv("../readfiles/loc_map.csv")

# Tidy dataset
readfile_tidy <- str_glue("../readfiles/tidy/")
fig_path = "../figs/manuscript/"

df_energy_tidy <- read_rds(paste0(readfile_tidy, "df_energy.rds"))
df_meta_tidy <- read_rds(paste0(readfile_tidy, "df_meta.rds"))
df_weather_tidy <- read_rds(paste0(readfile_tidy, "df_weather.rds"))
df_sprt_all_tidy <- read_rds(paste0(readfile_tidy, "df_sprt_all.rds"))
df_seq_FS_tidy <- read_rds(paste0(readfile_tidy, "df_seq_FS.rds"))
df_NRE_occ <- read_rds(paste0(readfile_tidy, "df_NRE_occ.rds"))
df_MD_tidy <- read_rds(paste0(readfile_tidy, "df_MD.rds"))
df_FS_tidy <- read_rds(paste0(readfile_tidy, "df_FS.rds"))
df_eui_tidy <- read_rds(paste0(readfile_tidy, "df_eui.rds"))
df_cont_MD_tidy <- read_rds(paste0(readfile_tidy, "df_cont_MD.rds"))
df_cont_FS_tidy <- read_rds(paste0(readfile_tidy, "df_cont_FS.rds"))
df_model_acc_tidy <- read_rds(paste0(readfile_tidy, "df_model_acc.rds"))

all_sites_tidy <- df_energy_tidy %>%
  select(site) %>%
  distinct() %>%
  arrange(site)

all_types_tidy <- df_energy_tidy %>%
  select(type) %>%
  mutate(type = as.factor(type)) %>%
  distinct()

all_names_tidy <- df_energy_tidy %>%
  select(name) %>%
  distinct(name)

# Messy dataset
readfile_messy <- str_glue("../readfiles/messy/")

df_energy_messy <- read_rds(paste0(readfile_messy, "df_energy.rds"))
df_meta_messy <- read_rds(paste0(readfile_messy, "df_meta.rds"))
df_weather_messy <- read_rds(paste0(readfile_messy, "df_weather.rds"))
df_sprt_all_messy <- read_rds(paste0(readfile_messy, "df_sprt_all.rds"))
df_seq_FS_messy <- read_rds(paste0(readfile_messy, "df_seq_FS.rds"))
df_MD_messy <- read_rds(paste0(readfile_messy, "df_MD.rds"))
df_FS_messy <- read_rds(paste0(readfile_messy, "df_FS.rds"))
df_eui_messy <- read_rds(paste0(readfile_messy, "df_eui.rds"))
df_cont_MD_messy <- read_rds(paste0(readfile_messy, "df_cont_MD.rds"))
df_cont_FS_messy <- read_rds(paste0(readfile_messy, "df_cont_FS.rds"))
df_FS_nsprt <- read_rds(paste0(readfile_messy, "df_FS_nsprt.rds"))
df_MD_nsprt <- read_rds(paste0(readfile_messy, "df_MD_nsprt.rds"))
df_seq_FS_nsprt <- read_rds(paste0(readfile_messy, "df_seq_FS_nsprt.rds"))
df_model_acc_messy <- read_rds(paste0(readfile_messy, "df_model_acc.rds"))

all_sites_messy <- df_energy_messy %>%
  select(site) %>%
  distinct() %>%
  arrange(site)

all_types_messy <- df_energy_messy %>%
  select(type) %>%
  mutate(type = as.factor(type)) %>%
  distinct()

all_names_messy <- df_energy_messy %>%
  select(name) %>%
  distinct(name)

# read functions
function_path <- "../functions/"
source(paste0(function_path, "model_fit.R"))
source(paste0(function_path, "model_pred.R"))
source(paste0(function_path, "prepost_plot.R"))
```

# Introduction

## Background

### Conventional M&V

Measurement and Verification (M&V) is the process of quantifying energy
savings from energy efficiency projects by comparing actual energy
consumption against a baseline, adjusting for factors like weather and
occupancy. This process ensures that improvements in energy performance
are accurately evaluated. In the United States, practitioners often
refer to ASHRAE Guideline 14, the International Performance Measurement
and Verification Protocol (IPMVP), and the Federal Energy Management
Program (FEMP) for standard guidelines [@doe_mv_2008,
@efficiency_valuation_organisation_international_2007,
@ashrae_ashrae_2014]. These guidelines outline standardized methods for
quantifying energy savings, whether through calibrated simulations or
monitored measurements for specific equipment or systems (isolation
methods) or for entire buildings (whole-building methods). In this
study, we will focus on the energy savings quantified at the
whole-building level where the measurements are obtained from utility
bills or whole-building meters. The corresponding M&V process required
by ASHRAE Guideline 14, which we refer to as the convention method in
this paper. Typically, the process begins with baseline measurements
taken over a year before implementing any energy-efficiency retrofit,
followed by the same measurement procedure during the intervention
period. After collecting two years of data, an M&V analyst fits an
energy prediction model, using variables such as outdoor temperature and
time [@mathieu_quantifying_2011] to project baseline energy consumption
in the post-retrofit period. The difference between the counter-factual
baseline and the measured intervention represents the energy savings. A
key drawback of this method is its reliance on a two-year timeline to
quantify savings, during which baseline measurements can become outdated
due to changes in building performance caused by non-routine events
unrelated to the intervention. This limitation reduces the feasibility
of rapid M&V and complicates the quantification of estimation
uncertainty, thus impacting the accuracy and timeliness of savings
assessments.

### Randomized M&V

To address the limitations of conventional M&V methods and the
challenges posed by non-routine events, we propose a novel M&V method
that adopts the randomized crossover design, a concept borrowed from
medical and agricultural studies. Another improvement is that we
proposed a sequential evaluation framework and defined stopping criteria
to end the M&V if the target effect is detected. This is to avoid
unnecessary measurement collection over the full 2-year M&V cycle. The
full framework is detailed in another study with all stopping criteria
outlined <!--# TODO: Add references -->. In summary, this method
provides M&V analysts with a randomized schedule that alternates between
baseline and intervention implementation while ensuring balanced
sampling across days of the week. For example, given a 10-week M&V
period for 1 intervention, the balanced randomized schedule would
equally sample 5 Mondays with the baseline and 5 Mondays with the
intervention. The limitation of the randomized M&V is that it is only
applicable to a subset of retrofit projects such as control
interventions. However, for all applicable use cases, it allows analysts
to detect energy savings sequentially as the study progresses meaning
once the desired savings target is achieved, analysts can terminate the
M&V. The key advantage of randomization, which is one of the study
objectives, is that if control strategies are sampled with equal
probability, the influence of non-routine events is likely to be evenly
distributed between the baseline and intervention measurements. This
means that the savings estimate, calculated as the difference between
the two, effectively 'cancels out' the impact of these disturbances,
leading to a more accurate and unbiased assessment of the intervention's
impact.

### BDG2 dataset

The Building Genome Dataset 2 (BGD2) is an extensive open-access dataset
designed to advance research and development in building energy
efficiency and control strategies acting as a test-bed for modeling,
simulation, and algorithm development [@miller_building_2020]. BGD2
contains over 500 buildings' metadata and realistic operational
information from across North America and Europe, making it one of the
most comprehensive collections of building-related data available for
scientific use. The dataset includes various commercial building types
such as offices, education facilities, public, and retail buildings, and
provides detailed information on their physical characteristics (e.g.
enregy ratings, heating types and floor area) and hourly measurements of
chilled and hot water, electricity, gas usage as well as site outdoor
weather conditions.

For the purpose of this study, we only queried whole-building hourly
electricity usage. All building names and precise locations were erased
but the climate zone and city name were provided, which are shown in
Figure \@ref(fig:tidysite) and Figure \@ref(fig:messysite). In addition,
the measurements were pre-processed by the authors with timestamp
already converted to local time. We further described the data filtering
process in Section \@ref(method).

## Literature review

### Measurement and verification energy-efficient measures

Most research related to M&V for whole-building approach focuses on the
accuracy of baseline modeling, exploring model performance from simple
regression models to more complex machine learning techniques. One study
reviewed various models suitable for M&V applications as well as
selected input features [@alrobaie_review_2022] and another study
provided a definitive methodology to apply machine learning models for
M&V use cases [@gallagher_development_2018]. In addition, a few studies
investigated the critical performance metrics to evaluate the developed
baseline models [@granderson_automated_2015,
@granderson_development_2014] and compared a variety of models using
those metrics [@granderson_accuracy_2016]. These studies made
significant contributions by emphasizing the uncertainty associated with
the model-fitting process, a key factor in accurately determining energy
savings. Furthermore, other researchers addressed this issue by
leveraging statistical formulation and inference to improve baseline
energy models [@burkhart_measurement_2014, @heo_calibration_2012,
@walter_uncertainty_2014]. However, a gap still remains in the
literature regarding the rigorous quantification of uncertainties
directly associated with calculated savings, for instance, accounting
for the potential bias that baseline model might deteriorate (i.e.
becomes 'stale') over an extended period of pre- and post-analysis.

### Impact of non-routine events on building energy usage

A common non-routine event in energy-saving M&V projects is a change in
occupancy or a significant shift in occupant behavior. These changes can
greatly affect measured energy consumption in buildings and are
typically unrelated to the intervention strategy. For instance, during
the COVID-19 pandemic in 2020, most commercial buildings were
unoccupied, leading to a noticeable drop in energy bills despite no
energy-efficiency measures being implemented [@cai_impact_2024,
@chihib_impact_2021, @gaspar_assessing_2022, @kang_changes_2021].
Furthermore, subsequent research has shown that hybrid working modes,
allowing employees to work remotely, have persisted after the outbreak
of the pandemic [@aksoy_working_2022], adding further complexity to
energy consumption patterns due to evolved occupant behaviors with
higher flexibility [@gui_impact_2021, @mantesi_office_2022,
@xie_does_2021]. One study realized the limitation of current M&V
methods, which only consider adjusting for outdoor weather, is
insufficient and emphasized the importance of requiring matched
comparison groups to control for exogenous factors beyond weather
differences when comparing between baseline and intervention
[@demand_side_analytics_population_2022]. Another type of non-routin
event is filter clogging in air handling units due to particle
accumulation. This can cause supply fans to gradually consume more
energy to maintain required duct static pressure [@feng_newly_2019,
@zhai_full-scale_2017]. If M&V analysts are unaware of such changes and
lack an appropriate adjustment method (e.g., replacing filters before
the intervention begins), the savings could be underestimated as
increased energy use is incorrectly attributed to the intervention
rather than the mechanical issue.

### Randomized experimental design in other scientific fields

To address the research gap identified in existing M&V studies,
particularly the challenges posed by non-routine events, we applied a
randomized experimental design method---an approach commonly used in
other scientific disciplines. In clinical trials, for instance,
randomization is employed to determine the effect of a medical treatment
(such as a new drug) by randomly assigning participants to either a
control group (e.g., receiving a placebo) or a treatment group
[@angus_adaptive_2019, @burger_importance_2021, @lim_randomization_2019,
@wiley_crossover_2016]. The primary purpose of randomization is to block
confounding variables such as age, gender, and socioeconomic status when
evaluating treatment effects. In the context of buildings, a "treatment"
refers to a control retrofit, while the "placebo" represents the
existing baseline control. Unlike clinical trials, where participants
are randomly assigned, our approach randomizes treatment assignment
longitudinally for each individual building---an approach known as
n-of-1 trials [@gabler2011]. Although the BDG2 dataset allows for
randomization at a population level (e.g., across climate zones),
building owners are generally more interested in understanding the
effects of control retrofits specific to their own buildings, rather
than at a generalized population level.

## Objectives

As mentioned, the goal of an M&V project is to determine the
effect---typically energy savings---of an energy-efficient intervention.
In this study, we focus primarily on switchable interventions, which
often involve control retrofits. An example of such an intervention is a
control retrofit developed by a software-as-a-service company that
adjusts the chilled water plant's supply water temperature based on
outdoor weather conditions [@roa_field_2023,
@lee_simulationoptimization_2012, @qiu_chilled_2022]. Therefore, we
defined the M&V scenario as follows:

*"A company aims to sell its supply temperature reset control software
package to a customer, such as a building owner, with a guarantee that
it will reduce the building's electricity usage. If the building owner
decides to purchase the service, the company agrees to charge a service
fee based on a percentage of the measured energy savings."*

As required by the M&V scenario, we assessed the performance of both the
conventional and the novel randomized M&V methods by estimating the
intervention energy savings for all valid buildings in the dataset. By
conducting such analysis, we aim to:

1.  Compare the energy saving estimation accuracy between the
    conventional and the randomized method. This study extends the
    comparison to a large sample of buildings, covering a variety of
    types and climate zones. The comparison metrics include both
    estimation accuracy and M&V finishing timeline.

2.  Verify the enhanced robustness of the randomized method. By using
    realistic measurements from real-world buildings, which include
    various sources of noise, we aim to reflect the challenges faced by
    building analysts in real projects. As will be demonstrated in the
    following sections, the randomized approach is less impacted by
    non-routine events (i.e., measurement 'noise'), resulting in more
    reliable energy savings estimates.

3.  Demonstrate the implementation of the proposed randomized M&V method
    using a public available dataset. We ensured the reproducibility of
    the method by making the analysis code open source including
    randomized schedule generation, sequential statistical analysis,
    energy modeling and normalized saving calculation. Using the
    available open resources, building analysts should be able to
    seamlessly integrate and apply them in their own M&V projects.

# Method

We outlined the methodology of the study in Figure \@ref(fig:flowchart)
and extended several key components in this section.

```{r flowchart, fig.cap = "Flow chat showing the methodology for comparing the estimated savings of randomized M&V with the conventional M&V", out.width="50%"}

knitr::include_graphics(paste0(fig_path, "flowchart.png"))
```

## Building filtering

### 'Tidy' subset

In this study, we extracted the electricity measurements from the BDG2
dataset. On a first pass, we filtered out buildings with less noise
based on the following criteria:

1.  Missing values \< 1000: given the hourly resolution of all
    measurements, this is equivalent to 1.5 months of missing days.

2.  Mean electricity usage \> 0 kWh: target buildings should have active
    electricity usage.

3.  No statistical significant difference (P-value \> 0.05) between the
    two-year electricity usage: target buildings should have no change
    in the electricity usage between the two years.

4.  Target buildings should have known site location: buildings with
    anonymous location are excluded due to unavailable typical
    meteorological weather.

5.  Warehouse and parking types are excluded: target buildings have less
    demand flexibility to implement a chilled water setpoint reset
    control.

Therefor the resulting subset contains all buildings with 'tidy'
measurements. Figure \@ref(fig:tidysite) shows in total, the subset
contains `r nrow(all_names_tidy)` buildings of `r nrow(all_types_tidy)`
types.

```{r tidysite, fig.cap = "Site summary of the tidy building subset (counts < 2 are omitted for visualization; left: aggragated counts of buildings for each type; right: breakdown building counts for each building type at each location)", fig.width=8, fig.height=6}

set3 <- colorRampPalette(brewer.pal('Set3',n=12))
type_colors <- setNames(set3(13), all_types_messy$type)
  
p1 <- df_energy_tidy %>%
  group_by(type) %>%
  distinct(name) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  mutate(type = fct_reorder(type, n, .desc = F)) %>%
  ggplot(aes(x = 1, y = n, fill = as.factor(type))) +
  geom_col() +
  geom_text(aes(label = ifelse(n > 2, as.character(n), "")), color = "black", position = position_stack(vjust = 0.5)) +
  scale_y_continuous(expand = c(0, 0),
                     breaks = breaks_pretty(n = 4)) +
  scale_x_discrete(expand = c(0, 0.1)) +
  scale_fill_manual(values = type_colors) +
  labs(x = NULL,
       y = NULL,
       subtitle = "Combining all locations",
       fill = NULL) +
  theme(axis.text.x = element_blank(),
        panel.grid.major.y = element_line(color = "grey80"),
        legend.direction = "horizontal",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))
  
  p2 <- df_energy_tidy %>%
    left_join(df_loc, by = "site") %>% 
    group_by(location, type) %>%
    distinct(name) %>%
    summarise(n = n()) %>%
    mutate(proportion = n / sum(n),
           total = sum(n),
           ymax = cumsum(proportion),
           ymin = c(0, head(ymax, n = -1))) %>%
    mutate(label_pos = (ymax + ymin) / 2) %>%
    ungroup() %>%
    group_by(type) %>%
    mutate(order = sum(n)) %>%
    ungroup() %>%
    mutate(type = fct_reorder(type, order, .desc = F)) %>%
    ggplot(aes(ymax = ymax, ymin = ymin, xmax = 4, xmin = 3, fill = type)) +
    geom_rect() +
    coord_polar(theta = "y") +
    xlim(c(2, 4)) +
    facet_wrap(~ location, nrow = 3) +
    labs(x = NULL,
         y = NULL,
         subtitle = "For each location",
         fill = NULL) +
    scale_fill_manual(values = type_colors) +
    geom_text(aes(x = 3.5, y = label_pos, label = ifelse(n > 2, as.character(n), ""))) +
    geom_text(aes(x = 2, y = 0, label = paste0("Total\n", total)), color = "black") +
    theme(legend.direction = "horizontal",
          axis.text = element_blank(),
          plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))
  
  ggarrange(p1, p2,
            ncol = 2, nrow = 1,
            widths = c(0.2, 1),
            common.legend = TRUE,
            legend = "bottom") +
    plot_annotation(title = "Summary of building numbers and types for 'tidy' subset")
```

### 'Messy' subset

In reality, the 'tidy' subset is less representative of the measurements
typically collected from existing building stock, as whole-building
electricity measurements collected over two years often show more
variability the the filtering critieron. These variations can stem from
issues like sensor calibration errors or inherent changes in the
building, which, as previously discussed, can bias M&V results.
Therefore, to more realistically assess the robustness of the two M&V
method, we included an additional 'messy' subset which first exclude the
'tidy' subset and then re-apply the filtering rule with one amendment:

3.  $\frac{abs(E_{2017} - E_{2016})}{E_{2016}}< 25\%$: any increase or
    decrease of building electricity usage in the second year should be
    less than 25% of that in th first year.

Figure \@ref(fig:messysite) shows the summary of the 'messy' dataset,
which contains `r nrow(all_names_messy)` buildings in
`r nrow(all_types_messy)` types.

```{r messysite, fig.cap = "Site summary of the messy building subset (counts < 2 are omitted for visualization; left: aggragated counts of buildings for each type; right: breakdown building counts for each building type at each location)", fig.width=8, fig.height=8}

p1 <- df_energy_messy %>%
    group_by(type) %>%
    distinct(name) %>%
    summarise(n = n()) %>%
    ungroup() %>%
    mutate(type = fct_reorder(type, n, .desc = F)) %>%
    ggplot(aes(x = 1, y = n, fill = as.factor(type))) +
    geom_col() +
    geom_text(aes(label = ifelse(n > 10, as.character(n), "")), color = "black", position = position_stack(vjust = 0.5)) +
    scale_y_continuous(expand = c(0, 0),
                       breaks = breaks_pretty(n = 4)) +
    scale_x_discrete(expand = c(0, 0.1)) +
    scale_fill_manual(values = type_colors) +
    labs(x = NULL,
         y = NULL,
         subtitle = "Combining all locations",
         fill = NULL) +
    theme(axis.text.x = element_blank(),
          panel.grid.major.y = element_line(color = "grey80"),
          legend.direction = "horizontal",
          plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))
  
  p2 <- df_energy_messy %>%
    left_join(df_loc, by = "site") %>% 
    group_by(location, type) %>%
    distinct(name) %>%
    summarise(n = n()) %>%
    mutate(proportion = n / sum(n),
           total = sum(n),
           ymax = cumsum(proportion),
           ymin = c(0, head(ymax, n = -1))) %>%
    mutate(label_pos = (ymax + ymin) / 2) %>%
    ungroup() %>%
    group_by(type) %>%
    mutate(order = sum(n)) %>%
    ungroup() %>%
    mutate(type = fct_reorder(type, order, .desc = F)) %>%
    ggplot(aes(ymax = ymax, ymin = ymin, xmax = 4, xmin = 3, fill = type)) +
    geom_rect() +
    coord_polar(theta = "y") +
    xlim(c(2, 4)) +
    facet_wrap(~ location, nrow = 3) +
    labs(x = NULL,
         y = NULL,
         subtitle = "For each location",
         fill = NULL) +
    scale_fill_manual(values = type_colors) +
    geom_text(aes(x = 3.5, y = label_pos, label = ifelse(n > 1, as.character(n), ""))) +
    geom_text(aes(x = 2, y = 0, label = paste0("Total\n", total)), color = "black") +
    theme(legend.direction = "horizontal",
          axis.text = element_blank(),
          plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))
  
  ggarrange(p1, p2,
            ncol = 2, nrow = 1,
            widths = c(0.2, 1),
            common.legend = TRUE,
            legend = "bottom") +
    plot_annotation(title = "Summary of building numbers and types for 'messy' subset")
```

## Apply control intervention

Figure \@ref(fig:chwst) shows the algorithm for the proposed control
intervention that reset the chiller supply temperature based on the
outdoor weather conditions, which can be commonly found in the
literature [@lee_chilled_2022, @congradac_recognition_2012]. For both
strategies, we assume that the chiller is activated when the outdoor
temperature exceeds 10°C. The baseline strategy, representing the
existing measurements from the dataset, operates with a constant water
supply temperature. The intervention strategy, as illustrated in the
figure, adjusts the water supply temperature dynamically, resetting it
from 7°C to 12°C.

```{r chwst, fig.cap = "Proposed intervention strategy: chilled water supply temperature reset based on outdoor temperature", fig.width=8, fig.height=4}

data.frame(
  OAT = c(10, 15, 25, 30),  
  Baseline = c(6, 6, 6, 6),      
  Intervention = c(12, 12, 7, 7)
  ) %>% 
  pivot_longer(cols = c("Baseline", "Intervention"), names_to = "strategy", values_to = "value") %>% 
  ggplot(aes(x = OAT, y = value, color = strategy)) +
  geom_line(linewidth = 1.2) +
  scale_color_manual(values = ls_colors) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = c(4, 6, 8, 10, 12),
                     limits = c(5.5, 12.5),
                     labels = number_format(suffix = " °C")) +
  scale_x_continuous(expand = c(0, 0), 
                     breaks = c(10, 15, 20, 25, 30), 
                     labels = number_format(suffix = " °C")) +
  labs(x = "Outdoor temperature", 
       y = "Chilled water supply temperature", 
       color = NULL, 
       title = "Intervention logic: chilled water supply temperature reset") +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))

```

We mapped the chilled water supply temperature reset to the electrical
energy savings as: $$
\text{savings} = mean(E_{CHW}) \times 25\% \times \text{perc_savings}
$$

We assume on average, HVAC systems account for approximately 50% of a
building's total electricity consumption, and the chilled water plant
further consumes around 50% of the HVAC electricity. While this
assumption largely simplifies the diverse energy usage across various
building types, for the scope of this paper, we assume that 25% of the
total building electricity is used by the chilled water plant, $E_{CHW}$
[@us2012commercial]. Typically, the savings from an intervention are not
proportional to the building's hourly electricity usage, which is
generally the challenge for M&V. To address this, we mapped the
resulting electricity savings as a percentage of the plant's normal
operation, calculated as its mean electricity usage over the two-year
period. This percentage is influenced by factors such as outdoor
temperature ($OAT$), intervention supply water temperature
($T_{interv}$), baseline supply water temperature ($T_{base}$) and hour
of the day ($\delta_{occ}$, binary indicator whether during peak hours
from 9 AM to 4 PM).

$$
\text{perc_savings = }
\begin{cases}
0, & \text{ if } OAT < 10°C \\
\left[ \beta_{\text{temp}} \times (\text{T}_{\text{interv}} - \text{T}_{\text{base}}) \right] \times 
\left[ \beta_{\text{occ}} \times \delta_{occ} + \beta_{\text{unocc}} \times (1 - \delta_{occ})\right], & \text{ otherwise}
\end{cases}
$$

Parameters and their pre-defined values are summarized in the table
below. For simplicity, those parameters were not rigorously calibrated
for each building, and were used uniformly across the dataset.

|                        |                                                                  |       |
|-------------------|----------------------------------|-------------------|
| Parameter              | Description                                                      | Value |
| $\beta_{temp}$         | \% savings from setting $T_{interv}$ 1 °C higher than $T_{base}$ | 0.08  |
| $\beta_{occ}$          | \% savings adjustment during occupied hours                      | 1.2   |
| $\beta_{\text{unocc}}$ | \% savings adjustment during unoccupied hours                    | 0.8   |

: Table 1. Parameters for calculating the intervention savings.

## Apply example non-routine event

To illustrate the impact of non-routine events that are not properly
adjusted for, we developed three scenarios to quantify the energy
consumption changes associated with a hypothetical increase in
occupancy. Specifically, we assume that a rise in occupancy in 2016
(referred to as the "baseline year" when using the conventional method)
led to a 20% increase in whole-building measured electricity usage. The
three scenarios describe when this increase occurred: January to April
(S1), May to August (S2), and September to December (S3). This
hypothetical change was applied only to buildings in the "tidy" subset,
as these buildings were initially more likely to be free from
non-routine events.

## Run M&V methods

### Conventional M&V

As described in Section \@ref(introduction), conventional method for M&V
is time-consuming and unable to separate non-routine event impact from
measured savings. If using conventional method to estimate intervention
energy savings, the result (after 24 months) is calculated by the
difference between measured intervention and projected baseline in the
post-retrofit period. In this study, we leveraged a piece-wise linear
regression considering time-of-week and outdoor temperature (TOWT) as
independent variables for projection for the counter-factual baseline in
the post-retrofit period and normalization on typical meteorological
year [@mathieu_quantifying_2011].

### Randomized M&V

Compared to the conventional method, the randomized M&V approach offers
a more rapid and reliable estimation of energy savings. To apply this
method, analysts first define the target savings and stopping criteria.
Then they design a randomized switchback schedule and perform sequential
statistical tests, such as the sequential probability ratio test (SPRT),
to monitor savings as data is collected. Once the target savings are
detected, the analysts fit a prediction model (e.g. TOWT) to adjust for
differences in outdoor temperature, following the same adjustment
process as the conventional method. We provide example switchback
experimental design and stopping criteria thresholds below:

-   The HVAC system operates from 06:00 to 22:00 each day, so we use a
    daily sampling interval with the sampling time at midnight each day.

-   Block by day of the week with a block period of 12 weeks.

Stopping criteria are:

-   A minimum and maximum of 12 and 108 weeks respectively. The
    randomized schedule covers the entire two-year period but stopping
    criteria enables an early stop at the end of satisfied blocking
    period.

-   At least 80% of the drybulb temperature range in the annual TMY data
    sampled by both strategies.

-   Test for no carryover effect using a t-test with a p-value not
    exceeding a defined significance threshold of 0.05.

-   90% confidence that energy savings exceed or do not exceed 0% using
    the SPRT test. Medium effect size (d = 0.5) quantified by cohen's d
    and calculated SPRT statistics either falls below the lower
    threshold or exceeds the upper threshold.

-   As no baseline data is available, test with an equal sampling ratio
    (50% baseline, 50% intervention).

To remain consistency, savings normalization on typical meteorological
year is also modeled through TOWT.

# Results

## M&V methods comparison

In this section, we compare the performance of two M&V methods. The key
aspects of the assessment include: 1) time required to reach a saving
estimation: in most cases, a shorter M&V timeline reduces associated
cost and interruption for the building owner; and 2) saving estimation
accuracy: this is particularly important for any software-as-a-service
company to set a reasonable price with their customers.

### Savings estimation time

ASHRAE Guideline 14 offering minimum requirements for whole-building
measurement path states that the baseline period is either a full range
of all independent variables (typically outdoor weather conditions)
under normal facility operation or a 12-month worth of continuous
measurements. The same requirements also applies to intervention
installed in the post-retrofit period. Thus, the conventional M&V method
is likely to run over 24 months or even longer due to missing data. For
example if an analyst is asked to determine the energy savings of a
chilled water plant retrofit but missed most of the cooling season due
to delay in retrofit deployment, he/she needs to wait until the next
cooling season to measure the savings. If the randomized M&V method is
applicable, delays in retrofit deployment pose less risk to the building
owner since baseline are continuously monitored. Sampling at equal
probabilities (e.g., 50%/50% between baseline and intervention) helps to
balance the distribution of independent variables like outdoor weather
conditions across all sampled control strategies. As long as one
strategy is not sampled over a large number of consecutive days (e.g., 7
days or more), it is unlikely that the measurements of independent
variables will differ significantly between the control strategies.

Figure \@ref(fig:timeline) shows the average estimated timeline for each
building across all sites and climate conditions if using randomized M&V
for the applied chilled water supply temperature reset intervention. The
timeline figures for each individual building are attached in the
supplementary material. The figure shows all buildings can detect a
saving statistically from sampled measurements within 12 months, which
is equivalent to the minimum test criterion. Similar to the findings
from our pervious study, covering a sufficient range of outdoor weather
condition is the most stringent requirement. If target buildings are
located in a climate zone with more preferable outdoor weather
conditions such as California, covering 80% of the TMY range should only
take 3 \~ 4 months. In this case, the analyst can conclude the M&V
simultaneously if the blocking period ends at the same time. However,
given most buildings requires 6 months to achieve 80% of the TMY range,
all buildings can determine the savings, including associated
uncertainties, within 9 months---significantly shorter than the baseline
measurement period required by the conventional method.

```{r timeline, fig.cap="Randomized M&V timeline of satisfying key stopping criteria for all buildings", fig.width=8, fig.height=4}

df_time <- df_sprt_all_messy %>% 
  filter(seq != "final") %>% 
  bind_rows(df_sprt_all_tidy %>% filter(seq != "final")) %>% 
  select(name, seq, n_weeks)

count <- list()

for (i in seq(1, 36, by = 1)){

  df_sprt <- df_time %>% 
    filter(seq == "sprt",
           n_weeks <= i)
  
  df_eob <- df_time %>% 
    filter(seq == "eob",
           n_weeks <= i)
  
  df_temp <- df_time %>% 
    filter(seq == "temp", 
           n_weeks <= i)
  
  count[[i]] <- tibble("n_weeks" = i, 
                       "eob" = nrow(df_eob), 
                       "temp" = nrow(df_temp), 
                       "sprt" = nrow(df_sprt))
}

count <- bind_rows(count) 

count %>% 
  ggplot() +
  geom_bar(data = . %>% filter(n_weeks == 24 | n_weeks == 36), 
           aes(x = n_weeks, y = eob, fill = "Buildings satisfying all criteria"), 
           stat = "identity", 
           alpha = 0.8, 
           width = 1) +
  geom_line(aes(x = n_weeks, y = temp, color = "Buildings satisfying 80% TMY range"),
            alpha = 0.2) +
  geom_point(aes(x = n_weeks, y = temp, color = "Buildings satisfying 80% TMY range"), 
             size = 1.5) +
  geom_line(aes(x = n_weeks, y = sprt, color = "Buildings satisfying SPRT"),
            alpha = 0.2) +
  geom_point(aes(x = n_weeks, y = sprt, color = "Buildings satisfying SPRT"), 
             size = 1.5, 
             shape = 17) +
  geom_vline(xintercept = seq(12, 36, by = 12), lty = "dashed", color = "grey80") +
  annotate(geom = "text", 
           x = seq(3, 33, by = 12), 
           y = 700, 
           label = paste0("12-week block"), 
           alpha = 0.5) +
  scale_fill_manual(values = ls_colors) +
  scale_color_manual(values = ls_colors) +
  scale_x_continuous(expand = c(0, 0), 
                     limits = c(0, 38),
                     breaks = c(12, 24, 36), 
                     labels = c("12\nweeks", "24\nweeks", "36\nweeks")) +
  coord_cartesian(ylim = c(0, 720)) +
  labs(x = NULL, 
       y = "Number of buildings", 
       fill = NULL, 
       color = NULL, 
       title = "Overall timeline for buildings using randomized M&V") +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))

```

### Savings estimation accuracy

In this study, we define the overall target savings (i.e., the ground
truth) that an M&V analyst aims to detect as the mean reduction in
electricity consumption over a two-year period resulting from the
implementation of the chilled water supply temperature reset control.
This target can be expressed in terms of normalized savings, fractional
savings, or simply the measured difference between baseline and
intervention measurements. Due to different timeline required by the two
methods, we compare the conventional M&V savings at the end of the
two-year period with the randomized M&V savings after all criteria are
satisfied. Since those are the time in reality, an M&V analyst report
estimated savings.

Figure \@ref(fig:norm) shows the overall comparison of the savings
estimated for all buildings in both subsets normalized on the typical
meteorological year weather conditions of each site. In subplot a), the
narrower range and clustering of the true savings indicates the
dependence of the intervention effect on the outdoor weather condition,
which is intended after weather normalization. Sites with mild climate
all year round such as locations in California shows higher savings
potential above 10%, while locations with more extreme climate such as
Washington DC shows only 6% savings annually. In subplot b), the results
indicate that the conventional M&V method tends to estimate savings with
greater uncertainty, and its distribution median deviates from the true
savings. In comparison, the randomized method, which requires much less
time, shows more accurate and precise estimation results.

```{r norm, fig.cap="Comparison of annual fractional savings normalized on TMY weather conditions between conventional and randomized M&V method", fig.width=8, fig.height=4}

p1 <- df_FS_tidy %>% 
  bind_rows(df_FS_messy) %>% 
  filter(method == "true") %>% 
  mutate(method = "True savings") %>% 
  ggplot(aes(x = method, y = savings, fill = method)) +
  geom_errorbar(aes(ymin = min(savings), ymax = max(savings)), width = 0.2) +
  geom_boxplot(outlier.size = 2) +
  geom_text(aes(x = 1.35, 
                y = median(savings) + 1.5, 
                label = paste0("median: ", round(median(savings), digits = 0), "%")), 
            check_overlap = T) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     limits = c(0, 28), 
                     labels = number_format(suffix = "%")) +
  labs(x = NULL, 
       y = NULL, 
       fill = NULL) +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))

p2 <- df_FS_tidy %>% 
  bind_rows(df_FS_messy) %>% 
  pivot_wider(names_from = method, values_from = savings) %>% 
  left_join(df_seq_FS_tidy %>% 
              bind_rows(df_seq_FS_messy) %>% 
              filter(seq == "eob"), by = c("name", "site")) %>% 
  pivot_longer(c(conv, rand, FS), names_to = "parameter", values_to = "value") %>% 
  filter(parameter != "rand") %>% 
  mutate(parameter = as.factor(parameter), 
         parameter = recode_factor(parameter, 
                                   "conv" = "Conventional M&V", 
                                   "FS" = "Randomized M&V")) %>% 
  ggplot(aes(x = parameter, y = value, fill = parameter)) +
  stat_boxplot(geom ='errorbar', width = 0.5) +
  geom_boxplot(outlier.shape = NA) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     limits = c(0, 28)) +
  scale_fill_manual(values = ls_colors) +
  labs(x = NULL, 
       y = NULL, 
       fill = NULL) +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        axis.text.y = element_blank(),
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))

  ggarrange(p1, p2,
            labels = c("a)", "b)"),
            ncol = 2, nrow = 1,
            widths = c(0.5, 1),
            legend = "none") +
    plot_annotation(title = "Normalized annual fractional savings estimation comparison")
```

To assess accuracy at the individual building level, we calculated the
mean absolute difference between the true savings and the estimated
savings and normalized the results as a fraction of measured baseline
for generalized comparison. Figure \@ref(fig:tidyfrac) shows the
comparison between the two methods using the tidy subset. In this
comparison, we focused on the median and the 95th percentile of the
plotted distribution to minimize the influence of outliers. The results
indicate that the conventional method outperforms the randomized method
in this subset. This is mostly because the tidy subset includes
buildings with consistent usage patterns throughout the two-year period,
meaning the data used for regression model fitting closely aligns with
the conditions during the model prediction phase. In our case, this
justifies the TOWT model selection when there is no additional
adjustment needed for such pre- and post-analysis.

```{r tidyfrac, fig.cap="Absolute deviation of fractional savings from true target savings shown for the 'tidy' subset", fig.width=8, fig.height=4}

plot_data <- df_seq_FS_tidy %>% 
  filter(seq == "eob") %>% 
  left_join(df_FS_tidy %>% filter(scenario == "ref" & method == "true"), by = c("name", "site")) %>% 
  mutate(abs_diff = abs(savings - FS), 
         plot_max = max(abs_diff))

median_rand <- median(plot_data$abs_diff)
upper_rand <- quantile(plot_data$abs_diff, probs = 0.95)

p1 <- plot_data %>% 
  arrange(abs_diff) %>% 
  ggplot() +
  geom_bar(aes(x = seq(1, nrow(all_names_tidy), by = 1), y = abs_diff, fill = "Randomized M&V"), 
           stat = "identity", alpha = 0.5) +
  geom_hline(yintercept = median_rand, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = median_rand + 0.5, 
           x = 20, 
           geom = "text", 
           label = paste0("(", "50% buildings: < ", round(median_rand, digits = 1), " %)"),
           size = 4) +
  geom_hline(yintercept = upper_rand, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = upper_rand + 0.5, 
           x = 20, 
           geom = "text", 
           label = paste0("(", "95% buildings: < ", round(upper_rand, digits = 1), " %)"),
           size = 4) +
  scale_x_continuous(expand = c(0.02, 0), 
                     breaks = breaks_pretty(n = 3)) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     labels = number_format(suffix = " %"),
                     limits = c(0, max(plot_data$plot_max) + 0.5)) +
  scale_fill_manual(values = ls_colors) +
  labs(fill = NULL, 
       x = "Number of buildings", 
       y = "Absolute difference of fractional savings", 
       subtitle = "Randomized M&V") +
  coord_cartesian(ylim = c(0, 10)) +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))

plot_data <- df_FS_tidy %>% 
  filter(method != "rand") %>% 
  group_by(name) %>% 
  summarise(abs_diff = abs(diff(savings))) %>% 
  ungroup() %>% 
  mutate(plot_max = max(abs_diff))

median_conv <- median(plot_data$abs_diff)
upper_conv <- quantile(plot_data$abs_diff, probs = 0.95)

p2 <- plot_data %>% 
  arrange(abs_diff) %>% 
  ggplot() +
  geom_bar(aes(x = seq(1, nrow(all_names_tidy), by = 1), y = abs_diff, fill = "Conventional M&V"), 
           stat = "identity", alpha = 0.5) +
  geom_hline(yintercept = median_conv, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = median_conv + 0.5,
           x = 20, 
           geom = "text", 
           label = paste0("(", "50% buildings: < ", round(median_conv, digits = 1), " %)"),
           size = 4) +
  geom_hline(yintercept = upper_conv, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = upper_conv + 0.5, 
           x = 20,
           geom = "text", 
           label = paste0("(", "95% buildings: < ", round(upper_conv, digits = 1), " %)"),
           size = 4) +
  scale_x_continuous(expand = c(0.02, 0), 
                     breaks = breaks_pretty(n = 3)) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     labels = number_format(suffix = " %"),
                     limits = c(0, max(plot_data$plot_max) + 0.1)) +
  scale_fill_manual(values = ls_colors) +
  labs(fill = NULL, 
       x = "Number of buildings", 
       y = NULL, 
       subtitle = "Conventional M&V") +
  coord_cartesian(ylim = c(0, 10)) +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        axis.text.y = element_blank(),
        plot.margin = margin(t = 2, r = 7, b = 2, l = 0, unit = "mm"))

ggarrange(p1, p2,
          ncol=2, nrow=1,
          labels = c("a)", "b)"),
          align = "hv",
          legend="none") +
  plot_annotation(title = "Savings estimation accuracy comparison", 
                  subtitle = "using 'tidy' subset")

```

While these findings suggest that the conventional M&V method is
advantageous when a building maintains stable electricity usage over
time, such stability is rarely guaranteed in real-world scenarios. A
more realistic condition is shown in the messy subset in Figure
\@ref(fig:messyfrac). In this case, the randomized method demonstrates
consistent accuracy in savings estimation, even in the presence of
random measurement noise, implying strong robustness. In contrast, the
conventional method shows deviations exceeding 5% in approximately 50%
of all cases. Non-normalized mean absolute difference comparison plots
are provided in the supplementary material. The much deteriorated
performance of the conventional method highlights its vulnerability when
changes in electricity usage occur. This is because baseline projections
based on regression models become unreliable when non-routine events are
present. Non-routine events encompass all influential factors not
accounted for in the regression model, either due to their
impracticality to measure---such as hourly occupancy rates---or their
unpredictability---such as a sudden change in building use where an
office being converted into a warehouse. We dedicate the following
section to continue the discussion of the impact.

```{r messyfrac, fig.cap="Absolute deviation of fractional savings from true target savings shown for the 'messy' subset", fig.width=8, fig.height=4}

plot_data <- df_seq_FS_messy %>% 
  filter(seq == "eob") %>% 
  left_join(df_FS_messy %>% filter(scenario == "ref" & method == "true"), by = c("name", "site")) %>% 
  mutate(abs_diff = abs(savings - FS), 
         plot_max = max(abs_diff))

median_rand <- median(plot_data$abs_diff)
upper_rand <- quantile(plot_data$abs_diff, probs = 0.95)

p1 <- plot_data %>% 
  arrange(abs_diff) %>% 
  ggplot() +
  geom_bar(aes(x = seq(1, nrow(all_names_messy), by = 1), y = abs_diff, fill = "Randomized M&V"), 
           stat = "identity", alpha = 0.5) +
  geom_hline(yintercept = median_rand, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = median_rand + 1, 
           x = 220, 
           geom = "text", 
           label = paste0("(", "50% buildings: < ", round(median_rand, digits = 1), " %)"),
           size = 4) +
  geom_hline(yintercept = upper_rand, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = upper_rand + 1, 
           x = 220, 
           geom = "text", 
           label = paste0("(", "95% buildings: < ", round(upper_rand, digits = 1), " %)"),
           size = 4) +
  scale_x_continuous(expand = c(0.02, 0), 
                     breaks = breaks_pretty(n = 3)) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     labels = number_format(suffix = " %"),
                     limits = c(0, max(plot_data$plot_max) + 0.5)) +
  scale_fill_manual(values = ls_colors) +
  labs(x = "Number of buildings", 
       y = "Absolute difference of fractional savings", 
       fill = NULL, 
       subtitle = "Randomized M&V") +
  coord_cartesian(ylim = c(0, 25)) +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))

plot_data <- df_FS_messy %>% 
  filter(method != "rand") %>% 
  group_by(name) %>% 
  summarise(abs_diff = abs(diff(savings))) %>% 
  ungroup() %>% 
  mutate(plot_max = max(abs_diff))


median_conv <- median(plot_data$abs_diff)
upper_conv <- quantile(plot_data$abs_diff, probs = 0.95)

p2 <- plot_data %>% 
  arrange(abs_diff) %>% 
  ggplot() +
  geom_bar(aes(x = seq(1, nrow(all_names_messy), by = 1), y = abs_diff, fill = "Conventional M&V"), 
           stat = "identity", alpha = 0.5) +
  geom_hline(yintercept = median_conv, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = median_conv + 1,
           x = 220, 
           geom = "text", 
           label = paste0("(", "50% buildings: < ", round(median_conv, digits = 1), " %)"),
           size = 4) +
  geom_hline(yintercept = upper_conv, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = upper_conv + 1, 
           x = 220,
           geom = "text", 
           label = paste0("(", "95% buildings: < ", round(upper_conv, digits = 1), " %)"),
           size = 4) +
  scale_x_continuous(expand = c(0.02, 0), 
                     breaks = breaks_pretty(n = 3)) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     labels = number_format(suffix = " %"),
                     limits = c(0, max(plot_data$plot_max) + 0.1)) +
  scale_fill_manual(values = ls_colors) +
  labs(x = "Number of buildings", 
       y = NULL, 
       fill = NULL, 
       subtitle = "Conventional M&V") +
  coord_cartesian(ylim = c(0, 25)) +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        axis.text.y = element_blank(),
        plot.margin = margin(t = 2, r = 7, b = 2, l = 0, unit = "mm"))

ggarrange(p1, p2,
          ncol=2, nrow=1,
          labels = c("a)", "b)"),
          align = "hv",
          legend="none") +
  plot_annotation(title = "Savings estimation accuracy comparison", 
                  subtitle = "using 'messy' subset")

```

## Non-routine events impact on savings estimation

We included two examples in this section to illustrate the impact of
non-routine events on M&V savings estimation. In the first scenario, we
manually subtracted a portion of the electricity usage for a specific
period in the tidy subset to simulate occupancy-confounded measurements,
which were not originally present in the dataset. In the second
scenario, focusing on the messy subset, which already contains
underlying changes, we removed the intervention effect and applied both
M&V methods to assess which method could more accurately detect the
resulting zero 'savings.'

### Occupancy change

Although occupancy can be estimated in various ways, such as counting
check-ins, monitoring WiFi connections, or using indoor CO2
concentrations as a proxy, these methods are often not cost-effective
for routine operations in most buildings and may raise privacy concerns.
In the proposed scenario, we hypothesize that during the baseline
measurement period, one floor of tenants vacated the building, leaving
the space unoccupied for four months. This led to a fixed reduction in
electricity usage, approximated as 20% of the yearly average. We showed
the impact on TOWT model fitting in Figure \@ref(fig:occchange) where
from May 1st 2016 to August 31st 2016, the target building electricity
dropped. Subplot (a) displays the measured baseline data, including the
occupancy-related change, used as input for model training. Subplot (b)
shows the model's prediction results for the post-retrofit period. For
reference, we also plotted the correctly adjusted baseline (labeled as
'adjusted baseline') in the post-retrofit period. Since occupancy was
not considered an independent variable in the model, the baseline change
was incorrectly attributed to temperature and time variations shown as
the 'projected baseline', leading to underestimated savings estimation.

```{r occ}

n = 6

site_info <- df_energy_tidy %>%
    filter(name == all_names_tidy$name[n]) %>%
    select(site, type) %>%
    distinct()
  
site <- site_info$site
  
site_weather <- df_weather_tidy %>%
    filter(site == site_info$site) %>%
    select(timestamp, t_out) %>%
    group_by(timestamp) %>%
    summarise(t_out = mean(t_out)) %>%
    ungroup()

df_all <- df_energy_tidy %>%
    filter(name == all_names_tidy$name[n]) %>%
    select(timestamp, eload) %>%
    left_join(site_weather, by = "timestamp")
  
# Linear interpolation of baseline
df_all <- df_all %>%
  run_interpo()

plot_scale <- get_scale(df_all$base_eload)

df_hourly_conv <- df_all %>%
  run_reset()
  
df_base_conv <- df_hourly_conv %>%
    select(datetime,
           eload = base_eload,
           t_out) %>% 
    drop_na()

df_interv_conv <- df_hourly_conv %>%
    select(datetime,
           eload = interv_eload,
           t_out) %>% 
    drop_na()

    
change_start <- occ_params$change_start
change_end <- occ_params$change_end
change <- mean(df_base_conv$eload) * occ_params$change / 100

base_pre_meas <- df_base_conv %>%
  filter(datetime < as.Date("2017-01-01")) %>%
  mutate(eload = ifelse(month(datetime) >= month(change_start) & month(datetime) <= month(change_end), eload - change, eload))

# Baseline projection
towt_base <- base_pre_meas %>%
  model_fit()

df_towt <- df_interv_conv %>%
  filter(datetime >= as.Date("2017-01-01")) %>%
  select(time = datetime,
         temp = t_out,
         eload)

base_pos_proj <- model_pred(df_towt, towt_base) %>%
  rename("datetime" = "time") %>%
  select(datetime, towt, eload)

base_pos_true <- df_base_conv %>%
  filter(datetime >= as.Date("2017-01-01"))

interv_pos_meas <- df_interv_conv %>%
  filter(datetime >= as.Date("2017-01-01"))
```

```{r occchange, fig.cap="Illustration of occupancy change impact on TOWT model fitting and baseline projection in the post-retrofit period", fig.width=9, fig.height=4}

p1 <- ggplot() +
    geom_point(data = base_pre_meas %>%
                 slice_sample(n = 500),
               aes(x = datetime, y = eload, color = "Measured baseline"),
               size = 0.5,
               alpha = 0.3) +
    geom_smooth(data = base_pre_meas,
                aes(x = datetime, y = eload, color = "Measured baseline"), 
                formula = y ~ x, method = "loess") +
    scale_x_datetime(date_breaks = "2 months",
                     date_labels = "%b")  +
    scale_y_continuous(expand = c(0, 0),
                       breaks = breaks_pretty(n = 3),
                       labels = number_format(suffix = " kW")) +
    scale_color_manual(values = ls_colors) +
    coord_cartesian(ylim = plot_scale) +
    labs(x = NULL,
         y = NULL,
         color = NULL,
         title = NULL,
         subtitle = "Pre-retrofit period") +
    theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
          legend.direction = "horizontal",
          legend.position = "bottom",
          plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))
  
p2 <- ggplot() +
  geom_point(data = base_pos_proj %>%
               slice_sample(n = 500),
             aes(x = datetime, y = towt, color = "Projected baseline"),
             size = 0.5,
             alpha = 0.3) +
  geom_smooth(data = base_pos_proj,
              aes(x = datetime, y = towt, color = "Projected baseline"), 
              formula = y ~ x, method = "loess") +
  geom_point(data = base_pos_true %>%
               slice_sample(n = 500),
             aes(x = datetime, y = eload, color = "Adjusted baseline"),
             size = 0.5,
             alpha = 0.3) +
  geom_smooth(data = base_pos_true,
              aes(x = datetime, y = eload, color = "Adjusted baseline"), 
              formula = y ~ x, method = "loess") +
  geom_point(data = interv_pos_meas %>%
               slice_sample(n = 500),
             aes(x = datetime, y = eload, color = "Measured interv"),
             size = 0.5,
             alpha = 0.3) +
  geom_smooth(data = interv_pos_meas,
              aes(x = datetime, y = eload, color = "Measured interv"), 
              formula = y ~ x, method = "loess") +
  scale_x_datetime(date_breaks = "2 months",
                   date_labels = "%b")  +
  scale_y_continuous(expand = c(0, 0),
                     breaks = breaks_pretty(n = 3),
                     labels = number_format(suffix = " kW")) +
  scale_color_manual(values = ls_colors) +
  coord_cartesian(ylim = plot_scale) +
  labs(x = NULL,
       y = NULL,
       color = NULL,
       title = NULL,
       subtitle = "post-retrofit period") +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        axis.text.y = element_blank(),
        legend.direction = "horizontal",
        legend.position = "bottom",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))

ggarrange(p1, p2,
          ncol=2, nrow=1,
          labels = c("a)", "b)"),
          widths = c(1, 1),
          align = "v",
          legend="bottom") +
  plot_annotation(title = "Building energy consumption with added occupancy change")
```

Figure \@ref(fig:occsavings) shows the overall estimation accuracy
between the two M&V methods where the accuracy is indicated as a
difference-in-difference value:

$$
|FS_{conv} - FS_{true}| - |FS_{rand} - FS_{true}|
$$

Therefore, a positive value indicates that the randomized method
provides an estimation more closely aligned with the true target
savings. The bar plot shows the difference-in-difference of the
calculated fractional savings ($FS$) for each target building and the
dotted line shows the absolute deviation of randomized method (i.e.
$|FS_{rand} - FS_{true}|$ ) as a reference. In addition, we showed the
averaged difference-in-difference metric for each site in the figure,
quantifying how much more accurate the randomized method is compared to
the conventional method. As a result, across all sites, the randomized
method consistently outperforms the conventional method and the values
of dotted line show similar results compared to Figure
\@ref(fig:tidyfrac) further implying that the non-routine event has
negligible influence on the randomized method.

```{r occsavings, fig.cap="Savings estimation accuracy comparison between two M&V methods with added occupancy change (with the average difference-in-difference average on each location displayed at the bottom).", fig.width=9, fig.height=4}
s <- 'S2'
dev_conv <- df_NRE_occ %>%
  left_join(df_loc, by = "site") %>% 
  filter(scenario == s) %>%
  filter(method != "rand") %>%
  group_by(name, location, scenario) %>%
  summarise(conv = abs(diff(savings))) %>%
  ungroup()

dev_rand <- df_NRE_occ %>%
  left_join(df_loc, by = "site") %>% 
  filter(scenario == s) %>%
  filter(method != "conv") %>%
  group_by(name, location, scenario) %>%
  summarise(rand = abs(diff(savings))) %>%
  ungroup()

dev_FS <- dev_rand %>%
  left_join(dev_conv, by = c("name", "location", "scenario")) %>% 
  mutate(diff_in_diff = conv - rand)

mean_diff <- dev_FS %>%
  group_by(location) %>%
  summarise(mean = round(mean(diff_in_diff), digits = 1),
            pos = round(n() / 2) + 1,
            .groups = 'keep')

dev_FS %>%
  ggplot(aes(group = location)) +
  geom_line(aes(x = name, y = rand, color = "Randomized M&V")) +
  geom_point(aes(x = name, y = rand, color = "Randomized M&V"), alpha = 0.8) +
  geom_col(aes(x = name, y = diff_in_diff), position = "identity", alpha = 0.2, fill = "#78c679") +
  facet_wrap(~location, nrow = 1, scales = "free_x") +
  scale_y_continuous(expand = c(0.1, 0),
                     breaks = breaks_pretty(n = 4), 
                     labels = number_format(suffix = "%")) +
  geom_text(data = mean_diff,
            aes(x = pos, y = -.5, group = location, label = paste0(mean, "%"))) +
  scale_color_manual(values = ls_colors) +
  labs(x = NULL,
       fill = NULL,
       y = "Difference-in-difference of fractional savings",
       color = NULL, 
       title = "Savings estimation accuracy comparison for non-routine events", 
       subtitle = "using 'tidy' subset") +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        axis.text.x = element_blank(),
        legend.direction = "horizontal",
        legend.position = "bottom",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))
```

### No-saving detection

As previously mentioned, the 'savings' detected in commercial buildings
during the pandemic were largely confounded by null occupancy. In other
words, if no intervention is applied or the intervention effect is known
to be null (e.g., constantly overridden by the baseline), an ideal M&V
method should detect no savings. Given that the messy dataset allows for
up to a 25% annual usage change in the original dataset, a more reliable
M&V method should inform the analyst that no savings occurred prior to
the addition of the intervention. To test this, we removed the chilled
water plant reset effect from the sampled days and assessed whether the
M&V methods could correctly detect zero savings.

```{r nosavings, fig.cap="Comparison of no intervention effect detection results (with 0% as true annual fractional savings) between conventional and randomized M&V method.", fig.width=6, fig.height=3}

df_FS_nsprt %>% 
  pivot_wider(names_from = method, values_from = savings) %>% 
  left_join(df_seq_FS_nsprt %>% filter(seq == "eob"), by = c("name", "site")) %>% 
  pivot_longer(c(true, conv, rand, FS), names_to = "parameter", values_to = "value") %>% 
  filter(parameter != "true" & parameter != "rand") %>% 
  mutate(parameter = as.factor(parameter), 
         parameter = recode_factor(parameter, 
                                   "conv" = "Conventional M&V", 
                                   "FS" = "Randomized M&V")) %>% 
  ggplot(aes(x = parameter, y = value, fill = parameter)) +
  stat_boxplot(geom ='errorbar', width = 0.2) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", linewidth = 1.2) +
  annotate(geom = "text", 
           x = 0.7, 
           y = 0.5, 
           color = "black",
           label = "True savings = 0") +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 5), 
                     limits = c(0, 16), 
                     labels = number_format(suffix = "%")) +
  scale_fill_manual(values = ls_colors) +
  labs(x = NULL, 
       y = NULL, 
       fill = NULL, 
       title = "Normalized confounded annual fractional savings comparison") +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "none",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))
```

Figure \@ref(fig:nosavings) shows that the conventional M&V method in
average detected 5% savings when there should be none. The randomized
method on the other hand is able to provide an estimation much closer to
0% with reduced uncertainty. This improvement is largely due to the
randomized sampling approach, where the two strategies (baseline and
intervention) are sampled at a 50%/50% ratio. This ensures that any
changes or disturbances additional to the intervention implementation,
such as concurrent lighting retrofits, are evenly distributed across
both strategies, balancing their effects.

# Discussion

## TOWT modeling accuracy

To assess modeling accuracy, we used the Coefficient of Variation of
Root-Mean Squared Error, or CV(RMSE) as the error metric. Since this
metric is calculated as a normalized value, it is useful to compare
different model fitting results. Guideline 14 requires that
whole-building baseline model fitting accuracy should maintain a
CV(RMSE) lower than 30% [@ashrae_ashrae_2014]. In addition one study
focusing on the baseline energy data-driven model fitting indicates that
TOWT performs as accurate as other more advanced machine learning models
[@granderson_accuracy_2016] and the calculated CV(RMSE) distribution for
a large sample of commercial buildings indicates a median of 20%. Figure
\@ref(fig:towtacc)shows the distribution of model fitting accuracy,
calculated separately for the two measurement sets. The box plot
provides a statistical summary of the accuracy data points, with error
bars highlighting any points beyond the range, which should be
considered outliers. The results show that the TOWT model's performance
in this study aligns with, and is even slightly better than, the
performance reported in the literature. The improved results can be
attributed to relatively strict data filtering criteria for
pre-processing described in Section \@ref(method).

```{r towtacc, fig.cap="TOWT model fitting accuracy distribution for all buildings included (with each data point representing one building)", fig.width=8, fig.height=4}

df_model_acc_messy %>% 
  mutate(group = "Messy subset") %>% 
  rbind(df_model_acc_tidy %>% mutate(group = "Tidy subset")) %>% 
  mutate(group = as.factor(group)) %>% 
  ggplot(aes(x = group, y = cvrmse)) +
  stat_boxplot(geom ='errorbar', width = 0.1) +
  geom_boxplot(outlier.shape = NA, width = 0.25) +
  geom_jitter(position = position_jitter(0.1), alpha = 0.1, size = 1.2) +
  geom_text(aes(x = group, y = median, label = paste0(round(median, digits = 0), " %")), 
            data = . %>% 
              group_by(group) %>% 
              summarise(median = median(cvrmse)) %>% 
              ungroup(), 
            position = position_nudge(x = 0.25)) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     labels = number_format(suffix = " %")) +
  coord_cartesian(ylim = c(0, 50)) +
  labs(x = NULL, 
       y = NULL, 
       color = NULL, 
       title = "TOWT model fitting accuracy", 
       subtitle = "CV(RMSE)") +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "none",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))
```

The limitation of regression models is that despite they capture well on
the mean building energy consumption but can underestimate the 15-min
daily peak load [@granderson2021], which is not useful for assessing
savings for demand response events.

## Sampling ratio for randomized M&V

Another advantage of using randomized M&V is the flexibility of changing
sampling ratio after the target savings detected. For instance, the
building owner can continue sampling at a 50%/50% ratio between the
baseline and the intervention to further reduce the uncertainty
associated with the savings. Alternatively, they could switch to 100%
intervention to maximize savings on the utility bill, though this
approach risks the baseline becoming outdated. A middle-ground approach
would be to sample at an 20%/80% ratio between the baseline and the
intervention. Through this way, the software-as-a-service company can
accurately model future baseline changes and adjust customers' bill
accordinly with minimum baseline days sampled. To demonstrate, figure
\@ref(fig:cont) shows after the analyst reports the randomized M&V
results indicated in Figure \@ref(fig:timeline), a new schedule sampling
at 20%/80% was implemented till the end of the year. Similarly, we
calculated the accuracy metric as the absolute deviation from the annual
true savings.

```{r cont, fig.cap="Randomized M&V absolute deviation of fractional savings from true target savings for a whole year with more intervention days sampled after all stopping criteria satisfied", fig.width=8, fig.height=4}

plot_data <- df_cont_FS_tidy %>% 
  rename(cont = FS) %>% 
  left_join(df_FS_tidy %>% filter(scenario == "ref" & method == "true"), by = c("name", "site")) %>% 
  mutate(abs_diff = abs(savings - cont), 
         plot_max = max(abs_diff))

median_rand <- median(plot_data$abs_diff)
upper_rand <- quantile(plot_data$abs_diff, probs = 0.95)

p1 <- plot_data %>% 
  arrange(abs_diff) %>% 
  ggplot() +
  geom_bar(aes(x = seq(1, nrow(all_names_tidy), by = 1), y = abs_diff, fill = "Randomized M&V"), 
           stat = "identity", alpha = 0.5) +
  geom_hline(yintercept = median_rand, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = median_rand + 0.5, 
           x = 20, 
           geom = "text", 
           label = paste0("(", "50% buildings: < ", round(median_rand, digits = 1), " %)"),
           size = 4) +
  geom_hline(yintercept = upper_rand, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = upper_rand + 0.5, 
           x = 20, 
           geom = "text", 
           label = paste0("(", "95% buildings: < ", round(upper_rand, digits = 1), " %)"),
           size = 4) +
  scale_x_continuous(expand = c(0.02, 0), 
                     breaks = breaks_pretty(n = 3)) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     labels = number_format(suffix = " %"),
                     limits = c(0, max(plot_data$plot_max) + 0.5)) +
  scale_fill_manual(values = ls_colors) +
  labs(x = "Number of buildings", 
       y = "Absolute difference of fractional savings", 
       fill = NULL, 
       subtitle = "Tidy subset") +
  coord_cartesian(ylim = c(0, 25)) +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        plot.margin = margin(t = 2, r = 7, b = 2, l = 2, unit = "mm"))


plot_data <- df_cont_FS_messy %>% 
  rename(cont = FS) %>% 
  left_join(df_FS_messy %>% filter(scenario == "ref" & method == "true"), by = c("name", "site")) %>% 
  mutate(abs_diff = abs(savings - cont), 
         plot_max = max(abs_diff))

median_rand <- median(plot_data$abs_diff)
upper_rand <- quantile(plot_data$abs_diff, probs = 0.95)

p2 <- plot_data %>% 
  arrange(abs_diff) %>% 
  ggplot() +
  geom_bar(aes(x = seq(1, nrow(all_names_messy), by = 1), y = abs_diff, fill = "Randomized M&V"), 
           stat = "identity", alpha = 0.5) +
  geom_hline(yintercept = median_rand, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = median_rand + 0.5, 
           x = 220, 
           geom = "text", 
           label = paste0("(", "50% buildings: < ", round(median_rand, digits = 1), " %)"),
           size = 4) +
  geom_hline(yintercept = upper_rand, 
             linetype = "dashed", 
             color = "black") +
  annotate(y = upper_rand + 0.5, 
           x = 220, 
           geom = "text", 
           label = paste0("(", "95% buildings: < ", round(upper_rand, digits = 1), " %)"),
           size = 4) +
  scale_x_continuous(expand = c(0.02, 0), 
                     breaks = breaks_pretty(n = 3)) +
  scale_y_continuous(expand = c(0, 0), 
                     breaks = breaks_pretty(n = 3), 
                     labels = number_format(suffix = " %"),
                     limits = c(0, max(plot_data$plot_max) + 0.1)) +
  scale_fill_manual(values = ls_colors) +
  labs(x = "Number of buildings", 
       y = NULL, 
       fill = NULL, 
       subtitle = "Messy subset") +
  coord_cartesian(ylim = c(0, 25)) +
  theme(panel.grid.major.y = element_line(color = "grey80", linewidth = 0.25),
        legend.direction = "horizontal",
        legend.position = "bottom",
        axis.text.y = element_blank(),
        plot.margin = margin(t = 2, r = 7, b = 2, l = 0, unit = "mm"))

ggarrange(p1, p2,
          ncol=2, nrow=1,
          labels = c("a)", "b)"),
          align = "hv",
          legend="none") +
  plot_annotation(title = "Randomized M&V savings estimation accuracy comparison with continue sampling included", 
                  subtitle = "20%/80% baseline/intervention")
```

The plot shows the deviation remains consistent in the tidy subset
comapred to Figure \@ref(fig:tidyfrac) but increased slightly in the
messy subset compare to to Figure \@ref(fig:messyfrac). With unbalanced
sampling ratio, there is a trade-off for estimation accuracy. But
compared with conventional method, this is still a preferred approach.
Most importantly, this approach allows customers to realize a proportion
of expected savings while documenting baseline measurement. For example,
opting for an early stop at 24 or 36 weeks with 50% intervention,
followed by re-sampling at 80% until the year's end (\~another 20
weeks), would enable customers to capture about 65% of the full-range
savings.

## Limitations and future study

We identify two key limitations in this study:

1.  Application of control intervention: Although the primary focus is
    on accurately detecting intervention effects rather than validating
    their broader impact, the simulated intervention remains somewhat
    generic considering the diverse building types and climate zones in
    the BDG2 dataset. For simplicity, we applied the parameters listed
    in Table 1 uniformly across all buildings. Yet, in some cases,
    raising the water temperature by 1°C might yield more or less than
    8% in electricity savings due to target buildings' demand
    flexibility.
2.  Design of the randomized switchback experiment: In this study, we
    assumed a daily sampling interval would suffice for most commercial
    buildings, but exceptions exist. Buildings with significant thermal
    lag, such as those with heavy concrete construction, hot water
    tanks, or Thermally Active Building Systems (TABS), may experience
    carryover effects. In these cases, the impact of one day's control
    strategy can influence subsequent measurements due to thermal
    storage. For example, if chilled water is pre-charged in the thermal
    mass at the end of a sampled intervention day and the control
    swicthes to baseline at 12 AM the following day, the analyst would
    observe lower energy consumption in that sampled baseline day. While
    this study does not account for carryover effects, we recommend
    using a 3-day sampling interval and excluding non-consecutive days
    in practice to 'wash out' residual effects from previous strategies.

For future work, our main objective is to extend the application of the
proposed randomized M&V approach. For instance, a customer may want to
know whether Model Predictive Control (MPC) can reduce energy bills
under a dynamic pricing structure or estimate the Return on Investment
(ROI) for a retrofit. Or whether a load shift control can save
operational cost by shifting load out of a given time window such grid
peak price/emissions period. We also believe that this approach could be
adapted to analyze the effects of other retrofit interventions at a
population level. Additionally, we aim to demonstrate that the
randomized method and sequential analysis framework can be applied to
various performance metrics, including indoor air quality, operational
carbon emissions, and thermal comfort.

# Conclusion

This research demonstrated the application of a novel whole-building
measurement and verification (M&V) method, comparing its performance to
the conventional approach outlined in ASHRAE Guideline 14 using a large,
open-source commercial building dataset. The proposed M&V method
leverages the randomized experimental design concept from other
scientific fields, along with statistical sequential inference
techniques, to determine when target savings are detected. We used a
virtual control retrofit case---resetting the chilled water setpoint
based on outdoor weather conditions---and applied it to over 500
filtered commercial buildings. By comparing the savings estimations of
the conventional method with the novel randomized method, we found that
the randomized approach provides faster and more robust savings
estimations.

Specifically, we showed that throughout 7 climate zones assessed in this
study, the randomized M&V can provide a saving estimation by 36 weeks
(with the majority finishes by 24 weeks) once all stopping criteria
satisfied. In contrast, the conventional method requires a full range of
baseline and intervention measurements under normal operating
conditions, typically taking 6-9 months for each phase. Most
importantly, Furthermore, we verified that with reduced M&V timeline the
randomized method can estimate savings more accurately than the two-year
conventional method.

We also evaluated the impact of non-routine events on the proposed M&V
method by: 1) introducing a known change, such as occupancy-induced
energy reductions, and 2) detecting when no intervention was applied in
buildings with marginal energy consumption differences. In both cases,
we demonstrated that baseline model fitting could be biased, while
randomization effectively blocked confounding effects, ensuring the
robustness of savings estimations.

Although the limitation of the method is that it only applies to a
subset of all M&V use cases (i.e., strategies that can be switched on
and off), we believe its true value lies in the usefulness and
conviencience for most control retrofit validation in the field test.

# Acknowledgements

# References
