return(df_interv)
}
# Function defined to interpolate NAs
run_interpo <- function(df_all){
na_counts <- df_all %>%
mutate(date = as.Date(timestamp)) %>%
group_by(date) %>%
summarize(na_hours = sum(is.na(eload)))
# Filter out days with more than half of the hours having NAs
valid_days <- na_counts %>%
filter(na_hours <= 12) %>%
pull(date)
df_filtered <- df_all %>%
filter(as.Date(timestamp) %in% valid_days)
df_filtered <- df_filtered %>%
mutate(across(c(eload, t_out), ~ zoo::na.approx(., na.rm = FALSE))) %>%
rename(datetime = timestamp,
base_eload = eload)
return(df_filtered)
}
# Function defined to find end of blocking period
get_eob <- function(sprt_res, sprt_overlap_base, sprt_overlap_interv){
sprt_check <- sprt_res %>% filter(flag == 1) %>% slice(1) %>% .$n_weeks
bt_check <- sprt_overlap_base %>% filter(flag == 1) %>% .$n_weeks
it_check <- sprt_overlap_interv %>% filter(flag == 1) %>% .$n_weeks
eob <- seq(block_params$block_unit, sprt_param$n_weeks, by = block_params$block_unit)
return(eob[eob >= max(c(sprt_check, bt_check, it_check))][1])
}
# Function defined to get sequential test results timeline
get_timeline <- function(sprt_res, sprt_overlap_base, sprt_overlap_interv){
sprt <- sprt_res %>% filter(flag == 1) %>% slice(1) %>% .$n_weeks
if (identical(sprt, integer(0))) {
sprt <- 48
}
return(list(name = name,
site = site,
sprt = sprt,
base_temp = sprt_overlap_base %>% filter(flag == 1) %>% .$n_weeks,
interv_temp = sprt_overlap_interv %>% filter(flag == 1) %>% .$n_weeks,
eob = get_eob(sprt_res, sprt_overlap_base, sprt_overlap_interv),
final = sprt_param$n_weeks))
}
# Function defined to get sequential mean difference savings
get_mdsaving <- function(timeline, sprt_res){
sprt_check <- timeline$sprt
temp_check <- max(timeline$base_temp, timeline$interv_temp)
eob <- timeline$eob
final <- sprt_param$n_weeks
return(list(name = name,
site = site,
sprt = sprt_res %>% filter(n_weeks == sprt_check) %>% .$ns_stat,
temp = sprt_res %>% filter(n_weeks == temp_check) %>% .$ns_stat,
eob = sprt_res %>% filter(n_weeks == eob) %>% .$ns_stat,
final = sprt_res %>% filter(n_weeks == final) %>% .$ns_stat))
}
# Function defined to get sequential normalized annual savings
get_nmsaving <- function(timeline, sprt_res){
sprt_check <- timeline$sprt
temp_check <- max(timeline$base_temp, timeline$interv_temp)
eob <- timeline$eob
final <- sprt_param$n_weeks
return(list(name = name,
site = site,
sprt = sprt_res %>% filter(n_weeks == sprt_check) %>% .$annual_saving,
temp = sprt_res %>% filter(n_weeks == temp_check) %>% .$annual_saving,
eob = sprt_res %>% filter(n_weeks == eob) %>% .$annual_saving,
final = sprt_res %>% filter(n_weeks == final) %>% .$annual_saving))
}
# Function defined to get sequential fractional savings
get_frsaving <- function(timeline, dataframe){
sprt_check <- timeline$sprt
temp_check <- max(timeline$base_temp, timeline$interv_temp)
eob <- timeline$eob
final <- sprt_param$n_weeks
return_l <- list()
for (i in c(sprt_check, temp_check, eob, final)){
df <- dataframe %>%
mutate(week = interval(min(datetime), datetime) %>% as.numeric('weeks') %>% floor()) %>%
filter(week <= i)
# saving calculation as mean difference
FS_rand <- (mean(df %>% filter(strategy == 1) %>% .$eload) -
mean(df %>% filter(strategy == 2) %>% .$eload)) /
mean(df %>% filter(strategy == 1) %>% .$eload) * 100
return_l <- c(return_l, FS_rand)
}
return(list(name = name,
site = site,
sprt = return_l[[1]],
temp = return_l[[2]],
eob = return_l[[3]],
final = return_l[[4]]))
}
#### READ DATA ####
readfile_path <- str_glue("../readfiles/{run_params$type}/")
summaryfigs_path <- str_glue("../figs/{run_params$type}/site_summary/")
combifigs_path <- str_glue("../figs/{run_params$type}/comb_analysis/")
df_energy <- read_rds(paste0(readfile_path, "df_energy.rds"))
df_meta <- read_rds(paste0(readfile_path, "df_meta.rds"))
df_weather <- read_rds(paste0(readfile_path, "df_weather.rds"))
schedule_2_design <- read_csv(paste0(readfile_path, "../schedule_2.csv"))
schedule_3_design <- read_csv(paste0(readfile_path, "../schedule_3.csv"))
schedule_week_design <- read_csv(paste0(readfile_path, "../schedule_week.csv"))
all_sites <- df_energy %>%
select(site) %>%
distinct() %>%
arrange(site)
all_types <- df_energy %>%
select(type) %>%
mutate(type = as.factor(type)) %>%
distinct()
all_names <- df_energy %>%
select(name) %>%
distinct(name)
df_tmy <- get_tmy(all_sites$site)
#### INDIVIDUAL ####
# storing results
FS_ref <- list()
MD_ref <- list()
model_acc <- list()
seq_timeline <- list()
seq_mdsaving <- list()
seq_nmsaving <- list()
seq_frsaving <- list()
seq_timeline_interval_2 <- list()
seq_timeline_interval_3 <- list()
seq_nmsaving_interval_2 <- list()
seq_frsaving_interval_2 <- list()
seq_nmsaving_interval_3 <- list()
seq_frsaving_interval_3 <- list()
cont_saving <- list()
interval_saving <- list()
FS_tmy <- list()
schedule_week_design
n = 1
name <- all_names$name[n]
site_info <- df_energy %>%
filter(name == all_names$name[n]) %>%
select(site, type) %>%
distinct()
site <- site_info$site
ifelse(!dir.exists(file.path(str_glue("../figs/{run_params$type}/site_analysis/{site}/{name}"))), dir.create(file.path(str_glue("../figs/{run_params$type}/site_analysis/{site}/{name}"))), FALSE)
sitefigs_path <- str_glue("../figs/{run_params$type}/site_analysis/{site}/{name}")
site_weather <- df_weather %>%
filter(site == site_info$site) %>%
select(timestamp, t_out) %>%
group_by(timestamp) %>%
summarise(t_out = mean(t_out)) %>%
ungroup()
site_tmy <- df_tmy %>%
filter(site == site_info$site)
df_all <- df_energy %>%
filter(name == all_names$name[n]) %>%
select(timestamp, eload) %>%
left_join(site_weather, by = "timestamp")
# length check
if (nrow(df_all) != (366 + 365) * 24){
print("Incomplete/duplicate timestamp, please check")
} else {
print(paste0(name, " at ", site_info$site, " start"))
}
# Linear interpolation of baseline
df_all <- df_all %>%
run_interpo()
plot_scale <- get_scale(df_all$base_eload)
df_hourly_conv <- df_all %>%
run_reset()
# separate baseline and intervention
df_base_conv <- df_hourly_conv %>%
select(datetime,
eload = base_eload,
t_out) %>%
drop_na()
df_interv_conv <- df_hourly_conv %>%
select(datetime,
eload = interv_eload,
t_out) %>%
drop_na()
# Check prediction accuracy
towt_base <- df_base_conv %>%
filter(datetime < as.Date("2017-01-01")) %>%
model_fit()
df_towt <- df_base_conv %>%
filter(datetime < as.Date("2017-01-01")) %>%
select(time = datetime,
temp = t_out,
eload)
base_proj <- model_pred(df_towt, towt_base) %>%
rename("datetime" = "time") %>%
mutate(error = eload - towt)
cv_rmse <- mean(sqrt(base_proj$error ^ 2)) / mean(base_proj$eload) * 100
model_acc[[n]] <- tibble("name" = name,
"site" = site,
"cvrmse" = cv_rmse)
# TOWT baseline project for post retrofit period
towt_base <- df_base_conv %>%
filter(datetime < as.Date("2017-01-01")) %>%
model_fit()
df_towt <- df_interv_conv %>%
filter(datetime >= as.Date("2017-01-01")) %>%
select(time = datetime,
temp = t_out,
eload)
base_proj <- model_pred(df_towt, towt_base) %>%
rename("datetime" = "time")
#### RANDOMIZATION ####
schedule <- blocking(start_date = block_params$start_date,
n_weeks = block_params$n_weeks,
n_seasons = block_params$n_seasons,
seed = sample(1: 2^15, 1),
searches = 20,
jumps = 20,
treatments = 2,
consec = 1)
# schedule summary
schedule$weekday_summary
df_schedule <- schedule$schedule %>%
select(datetime = date,
strategy)
df_rand <- df_hourly_conv %>%
left_join(df_schedule, by = "datetime") %>%
fill(strategy, .direction = "down") %>%
filter(datetime <= as.Date("2016-01-01") + weeks(block_params$n_weeks)) %>%
pivot_longer(c(base_eload, interv_eload), names_to = "eload_type", values_to = "eload") %>%
filter((strategy == 1 & eload_type == "base_eload") | (strategy == 2 & eload_type == "interv_eload")) %>%
select(-eload_type) %>%
drop_na()
seed <- sample(c(1:20), 1)
# running on 2-day sampling interval
df_schedule_2 <- schedule_2_design %>%
select(datetime,
strategy = str_glue("strategy_{seed}")) %>%
mutate(switch = ifelse(strategy != lag(strategy), T, F)) %>%
mutate(switch = ifelse(row_number() == 1, F, switch))
df_rand_new <- df_hourly_conv %>%
left_join(df_schedule_2, by = "datetime") %>%
fill(c(strategy, switch), .direction = "down") %>%
filter(datetime <= as.Date("2016-01-01") + weeks(block_params$n_weeks)) %>%
pivot_longer(c(base_eload, interv_eload), names_to = "eload_type", values_to = "eload") %>%
filter((strategy == 1 & eload_type == "base_eload") | (strategy == 2 & eload_type == "interv_eload")) %>%
filter(switch == 0) %>%
select(-c(eload_type, switch)) %>%
drop_na()
# saving calculation as mean difference
rand_fs_2 <- (mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) -
mean(df_rand_new %>% filter(strategy == 2) %>% .$eload)) /
mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) * 100
# savings at timeline
rand_md_2 <- mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) - mean(df_rand_new %>% filter(strategy == 2) %>% .$eload)
rand_tmy_2 <- saving_norm(df_rand_new %>% mutate(week = NA), site_tmy)
seq_res <- seq_run(sprt_param, df_rand_new, site_tmy)
sprt_res <- seq_res$sprt_res
sprt_overlap_base <- seq_res$sprt_overlap_base
sprt_overlap_interv <- seq_res$sprt_overlap_interv
sample(c(1, 2), 1)
sample(c(1, 2), 1)
sample(c(1, 2), 1)
sample(c(1, 2), 1)
sample(c(1, 2), 1)
sample(c(1, 2), 1)
sample(c(1, 2), 1)
sample(c(1, 2), 1)
sample(c(1, 2), 1)
df_schedule_week <- schedule_week_design %>%
select(datetime,
strategy = str_glue("strategy_{seed}")) %>%
mutate(switch = ifelse(strategy != lag(strategy), T, F)) %>%
mutate(switch = ifelse(row_number() == 1, F, switch))
# running with weekly interval
seed_bi <- sample(c(1, 2), 1)
df_schedule_week <- schedule_week_design %>%
select(datetime,
strategy = str_glue("strategy_{seed_bi}")) %>%
mutate(switch = ifelse(strategy != lag(strategy), T, F)) %>%
mutate(switch = ifelse(row_number() == 1, F, switch))
View(df_schedule_week)
df_rand_new <- df_hourly_conv %>%
left_join(df_schedule_week, by = "datetime") %>%
fill(c(strategy, switch), .direction = "down") %>%
filter(datetime <= as.Date("2016-01-01") + weeks(block_params$n_weeks)) %>%
pivot_longer(c(base_eload, interv_eload), names_to = "eload_type", values_to = "eload") %>%
filter((strategy == 1 & eload_type == "base_eload") | (strategy == 2 & eload_type == "interv_eload")) %>%
filter(switch == 0) %>%
select(-c(eload_type, switch)) %>%
drop_na()
View(df_rand_new)
# saving calculation as mean difference
rand_fs_week <- (mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) -
mean(df_rand_new %>% filter(strategy == 2) %>% .$eload)) /
mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) * 100
# savings at timeline
rand_md_week <- mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) - mean(df_rand_new %>% filter(strategy == 2) %>% .$eload)
rand_tmy_week <- saving_norm(df_rand_new %>% mutate(week = NA), site_tmy)
View(df_rand_new)
dataframe <- df_rand_new
tmy <- site_tmy
# Run SPRT
# prepare sequential test dataset
sprt_hourly <- dataframe %>%
mutate(week = interval(min(datetime), datetime) %>% as.numeric('weeks') %>% floor())
sprt_daily <- dataframe %>%
group_by(datetime = floor_date(datetime, unit = "day")) %>%
summarise(strategy = unique(strategy),
power_ave = mean(eload, na.rm = TRUE),
t_out = mean(t_out, na.rm = TRUE)) %>%
ungroup()
# prepare dataframe for analysis
df_sprt <- sprt_daily %>%
mutate(strategy = as.factor(strategy),
strategy = recode_factor(strategy, "1" = "Baseline", "2" = "Intervention")) %>%
filter(strategy %in% c(param$baseline, param$strategy)) %>%
pivot_longer(cols = -c(datetime, strategy),
names_to = "parameter",
values_to = "value") %>%
mutate(week = interval(min(datetime), datetime) %>% as.numeric('weeks') %>% floor(),
value = value) %>%
filter(str_detect(parameter, param$parameter)) %>%
droplevels()
seq_res <- seq_run(sprt_param, df_rand_new, site_tmy)
# load weather file
weather <- tmy %>%
mutate(eload = NA) %>%
select(-site)
# normal energy saving calculation
towt_base <- dataframe %>%
resample(.) %>%
filter(strategy == 1) %>%
select(-strategy, -week) %>%
model_fit()
dataframe <- df_rand_new %>% mutate(week = NA)
# normal energy saving calculation
towt_base <- dataframe %>%
resample(.) %>%
filter(strategy == 1) %>%
select(-strategy, -week) %>%
model_fit()
towt_s2 <- dataframe %>%
resample(.) %>%
filter(strategy == 2) %>%
select(-strategy, -week) %>%
model_fit()
base_results <- model_pred(weather, towt_base) %>%
rename("datetime" = "time")
model <- towt_base
# get all info from input
amod <- model$model_occupied
bmod <- model$model_unoccupied
time <- dataframe$time
temp <- dataframe$temp
temp_knots <- model$model_input_options$calculated_temp_knots
# get all info from input
amod <- model$model_occupied
bmod <- model$model_unoccupied
time <- dataframe$time
dataframe <- weather
# get all info from input
amod <- model$model_occupied
bmod <- model$model_unoccupied
time <- dataframe$time
temp <- dataframe$temp
temp_knots <- model$model_input_options$calculated_temp_knots
occ_info <- model$model_input_options$occupancy_info
interval_minutes <- model$model_input_options$interval_minutes
# prepare interval of week for training data
minute_of_week <- (lubridate::wday(time) - 1) * 24 * 60 +
lubridate::hour(time) * 60 + lubridate::minute(time)
interval_of_week <- 1 + floor(minute_of_week / interval_minutes)
# which time intervals are 'occupied'?
occ_intervals <- occ_info[occ_info[, 2] == 1, 1]
# create an occupancy vector for training dataset
occ_vec <- rep(0, nrow(dataframe))
for (i in 1 : length(occ_intervals)) {
occ_vec[interval_of_week == occ_intervals[i]] <- 1
}
ok_occ <- occ_vec == 1
ok_occ[is.na(ok_occ)] <- TRUE
ftow <- factor(interval_of_week)
temp_mat <- create_temp_matrix(temp, temp_knots)
dframe <- data.frame(dataframe, ftow, temp_mat)
# make predictions for occupied
if (sum(ok_occ)){
amod_towt <- stats::predict(amod, select(dframe[ok_occ, ], -eload))
amod_results <- data.frame(dframe[ok_occ, ]$time, dframe[ok_occ, ]$eload, amod_towt)
names(amod_results) <- c('time','eload','towt')
} else {
amod_results <- data.frame()
}
# make predictions for unoccupied
if (sum(!ok_occ)){
bmod_towt <- stats::predict(bmod, select(dframe[!ok_occ, ], -eload))
bmod_results <- data.frame(dframe[!ok_occ, ]$time, dframe[!ok_occ, ]$eload, bmod_towt)
names(bmod_results) <- c('time','eload','towt')
} else {
bmod_results <- data.frame()
}
sum(!ok_occ)
bmod_towt <- stats::predict(bmod, select(dframe[!ok_occ, ], -eload))
bmod
bmod_towt <- stats::predict(bmod, select(dframe[!ok_occ, ], -eload))
# make predictions for unoccupied
if (sum(!ok_occ)){
bmod_towt <- stats::predict(bmod, select(dframe[!ok_occ, ], -eload))
bmod_results <- data.frame(dframe[!ok_occ, ]$time, dframe[!ok_occ, ]$eload, bmod_towt)
names(bmod_results) <- c('time','eload','towt')
} else {
bmod_results <- data.frame()
}
bmod
amod
seed_bi
seed_bi <- 1
df_schedule_week <- schedule_week_design %>%
select(datetime,
strategy = str_glue("strategy_{seed_bi}")) %>%
mutate(switch = ifelse(strategy != lag(strategy), T, F)) %>%
mutate(switch = ifelse(row_number() == 1, F, switch))
df_rand_new <- df_hourly_conv %>%
left_join(df_schedule_week, by = "datetime") %>%
fill(c(strategy, switch), .direction = "down") %>%
filter(datetime <= as.Date("2016-01-01") + weeks(block_params$n_weeks)) %>%
pivot_longer(c(base_eload, interv_eload), names_to = "eload_type", values_to = "eload") %>%
filter((strategy == 1 & eload_type == "base_eload") | (strategy == 2 & eload_type == "interv_eload")) %>%
filter(switch == 0) %>%
select(-c(eload_type, switch)) %>%
drop_na()
# saving calculation as mean difference
rand_fs_week <- (mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) -
mean(df_rand_new %>% filter(strategy == 2) %>% .$eload)) /
mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) * 100
# savings at timeline
rand_md_week <- mean(df_rand_new %>% filter(strategy == 1) %>% .$eload) - mean(df_rand_new %>% filter(strategy == 2) %>% .$eload)
rand_tmy_week <- saving_norm(df_rand_new %>% mutate(week = NA), site_tmy)
bmod
#### Setup ####
# use pacman
require(pacman)
# load libraries
pacman::p_load(tidyverse, lubridate, here, scales, slider, patchwork, # general
broom, ggpmisc, ggpubr, # linear models
RMV2.0, # TOWT model
sprtt, effsize) # sequential testing
# turn off scientific notation
options(scipen = 999)
# set default theme for ggplot
theme_set(theme_minimal())
# define base ggplot theme
theme_update(plot.title = element_text(size = 14, colour = "grey20", face = "bold", hjust = 0.5),
plot.subtitle = element_text(size = 10, colour = "grey20", face = "italic", hjust = 0.5, margin = margin(b = 10)),
plot.caption = element_text(size = 10, colour = "grey20", face = "italic", hjust = 0.5),
plot.background = element_rect(fill = "white", colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.text = element_text(size = 10),
strip.text = element_text(size = 10, color = "grey20", face = "bold"),
strip.background = element_blank())
#### READ ####
function_path <- "../functions/"
output_path <- "../readfiles/"
source(paste0(function_path, "rand_seq.R"))
#### GENERATION ####
# adding random sampling schedules
block_params <- list(start_date = "2016-01-01",
n_weeks = 108,
n_seasons = 9,
block_unit = 12,
pool = 20)
# schedule generation
exclude <- data.frame(date = NA)
# 2-day consecutive sampling
schedule_2_design <- data.frame()
schedule_3_design <- data.frame()
i <- 1
while (i <= block_params$pool){
schedule <- data.frame()
for (sample_start in as.list(seq(as.Date(block_params$start_date), as.Date(block_params$start_date) + weeks(block_params$n_weeks), by = block_params$block_unit * 7))){
sample_end = sample_start + weeks(block_params$block_unit) - days(1)
block <- rand_seq(sample_start, sample_end, 2, 2, exclude)
schedule <- rbind(schedule, block$decision_data)
}
df_schedule_2 <- schedule %>%
rename(datetime = date,
!!str_glue("strategy_{i}") := strategy)
if (nrow(schedule_2_design) == 0) {
schedule_2_design <- df_schedule_2
} else {
schedule_2_design <- left_join(schedule_2_design, df_schedule_2, by = "datetime")
}
# 3-day consecutive sampling
schedule <- data.frame()
for (sample_start in as.list(seq(as.Date(block_params$start_date), as.Date(block_params$start_date) + weeks(block_params$n_weeks), by = block_params$block_unit * 7))){
sample_end = sample_start + weeks(block_params$block_unit) - days(1)
block <- rand_seq(sample_start, sample_end, 3, 2, exclude)
schedule <- rbind(schedule, block$decision_data)
}
df_schedule_3 <- schedule %>%
rename(datetime = date,
!!str_glue("strategy_{i}") := strategy)
if (nrow(schedule_3_design) == 0) {
schedule_3_design <- df_schedule_3
} else {
schedule_3_design <- left_join(schedule_3_design, df_schedule_3, by = "datetime")
}
i <- i + 1
}
# weekly switching schedules
schedule_week_design <- data.frame(datetime = seq(as.Date(block_params$start_date),
as.Date(block_params$start_date) + weeks(block_params$n_weeks) - days(1),
by = "1 day")) %>%
mutate(n_weeks = floor(as.numeric(datetime - as.Date(block_params$start_date)) / 7)) %>%
mutate(strategy_1 = rep(sample(c(1, 2), 1), 7), block_params$n_weeks / 2) %>%
select(-n_weeks)
rep(sample(c(1, 2), 1), 7, block_params$n_weeks / 2)
rep(sample(c(1, 2), 1), 7, block_params$n_weeks)
